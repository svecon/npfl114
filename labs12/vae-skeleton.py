#!/usr/bin/env python
from __future__ import division
from __future__ import print_function

import datetime

import numpy as np
import tensorflow as tf
import tensorflow.contrib.layers as tf_layers

class VAENetwork:
    WIDTH, HEIGHT = 28, 28

    def __init__(self, z_dim, logdir, expname, threads=1, seed=42):
        self.z_dim = z_dim
        self.steps = 0

        # Create an empty graph and a session
        graph = tf.Graph()
        graph.seed = seed
        self.session = tf.Session(graph = graph, config=tf.ConfigProto(inter_op_parallelism_threads=threads,
                                                                       intra_op_parallelism_threads=threads))

        timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H%M%S")
        self.summary_dir = "{}/{}-{}".format(logdir, timestamp, expname)
        self.summary_writer = tf.train.SummaryWriter(self.summary_dir, flush_secs=10)

        def decoder(z):
            # TODO: Implement a decoder, which
            # - starts with z
            # - add fully connected hidden layer of size 500 + ReLU
            # - add fully connected hidden layer of size 500 + ReLU
            # - add fully connected output layer of size HEIGHT*WIDTH without activation function
            # - reshapes the output to [batch_size, 28, 28, 1]
            return ...

        def encoder(image):
            # TODO: Implement a encoder, which
            # - starts with image
            # - flattens image to [batch_size, HEIGHT*WIDTH]
            # - add fully connected hidden layer of size 500 + ReLU
            # - add fully connected hidden layer of size 500 + ReLU
            # - add two output layers
            #   - z_mean is computed using output layer of size self.z_dim without activation function
            #   - z_log_variance is computed using output layer of size self.z_dim without activation function
            # - return z_mean and z_log_variance
            return ...

        # Construct the graph
        with self.session.graph.as_default():
            # Inputs
            self.images = tf.placeholder(tf.float32, [None, self.HEIGHT, self.WIDTH, 1])

            # Encoder
            z_mean, z_log_variance = encoder(self.images)
            # TODO: compute epsilon as tf.random_normal of same shape as z_mean
            # and self.z as z_mean + epsilon * sqrt(exp(z_log_variance))
            epsilon = ...
            self.z = ...

            # Decoder
            generated_images_logits = decoder(self.z)
            self.generated_images = tf.nn.sigmoid(generated_images_logits)

            # Loss and training
            # TODO: reconstruction_loss is reduce_mean of the following:
            #   sigmoid_cross_entropy_with_logits on generated_images_logits and self.images, summed over all pixels
            #   of each image [i.e., summed over axes 1, 2, 3]
            reconstruction_loss = ...
            # Latent loss is KL between distribution generated by encoder and prior distribution of z
            latent_loss = tf.reduce_mean(
                -0.5 * tf.reduce_sum(1 + z_log_variance - tf.square(z_mean) - tf.exp(z_log_variance), 1)
            )
            loss = reconstruction_loss + latent_loss

            # TODO: Optimize loss using Adam
            self.training = ...

            # Summaries
            self.summary = tf.merge_summary([tf.scalar_summary("vae/loss", loss),
                                             tf.scalar_summary("vae/reconstruction_loss", reconstruction_loss),
                                             tf.scalar_summary("vae/latent_loss", latent_loss)])

            self.png_image_data = tf.placeholder(tf.float32)
            self.png_image = tf.image.encode_png(tf.image.convert_image_dtype(self.png_image_data, tf.uint8))

            # Initialize variables
            self.session.run(tf.initialize_all_variables())

    def sample_z(self, batch_size):
        return np.random.normal(size=[batch_size, self.z_dim])

    def predict(self, z):
        return self.session.run(self.generated_images, {self.z: z})

    def train(self, images):
        # TODO: train the VAE
        # - run self.training and collect self.summary using self.images=images
        # - store the summary
        _, summary = ...
        if self.steps % 100 == 0:
            self.summary_writer.add_summary(summary, self.steps)

        self.steps += 1

    def generate_images(self, n, step):
        # Generate nxn images
        random_images = self.predict(self.sample_z(n * n))

        # Generate 2n z-es and interpolate between the neighbours
        interpolated_z = []
        if self.z_dim == 2:
            # Use 2d grid for z-es
            starts, ends = np.stack([-2*np.ones(n), np.linspace(-2, 2, n)], -1), np.stack([2*np.ones(n), np.linspace(-2, 2, n)], -1)
        else:
            # Generate 2n random z-es
            starts, ends = self.sample_z(n), self.sample_z(n)
        for i in range(n):
            for w in np.linspace(0, 1, n):
                interpolated_z.append(starts[i] + (ends[i] - starts[i]) * w)
        interpolated_images = self.predict(interpolated_z)

        # Stack at first nxn random images, then 1xn empty images, and nxn interpolated images
        image = np.concatenate(
            map(lambda images: np.concatenate(list(images), axis=1), np.split(random_images, n, 0)) +
            [np.zeros([self.HEIGHT, self.WIDTH * n, 1])] +
            map(lambda images: np.concatenate(list(images), axis=1), np.split(interpolated_images, n, 0)),
            axis = 0
        )

        with open("{}/images{}.png".format(self.summary_dir, str(step).zfill(3)), "wb") as file:
            file.write(self.session.run(self.png_image, {self.png_image_data: image}))

if __name__ == "__main__":
    # Fix random seed
    np.random.seed(42)

    # Parse arguments
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--batch_size", default=100, type=int, help="Batch size.")
    parser.add_argument("--dataset", default="mnist", type=str, help="Directory name of the dataset.")
    parser.add_argument("--batches", default=100000, type=int, help="Number of batches to train.")
    parser.add_argument("--logdir", default="logs", type=str, help="Logdir name.")
    parser.add_argument("--threads", default=1, type=int, help="Maximum number of threads to use.")
    parser.add_argument("--z_dim", default=100, type=int, help="Dimension of Z.")
    args = parser.parse_args()

    # Load the data
    from tensorflow.examples.tutorials.mnist import input_data
    mnist = input_data.read_data_sets(args.dataset, reshape=False, validation_size=0)

    # Construct the network
    expname = "vae-dataset_{}-zdim_{}-batch_{}-batches_{}".format(args.dataset, args.z_dim, args.batch_size, args.batches)
    network = VAENetwork(args.z_dim, logdir=args.logdir, expname=expname, threads=args.threads)

    # Train
    for i in range(args.batches):
        images, _ = mnist.train.next_batch(args.batch_size)
        network.train(images)

        if i % 1000 == 0:
            network.generate_images(20, i//1000 + 1)
